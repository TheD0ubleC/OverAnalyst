import os
import joblib
import numpy as np
import constants

MODEL_DIR = "models"

# =========================
# ä½ä¼˜å…ˆçº§è‹±é›„ (äºŒç»´æ•°ç»„)
# =========================
# ä¾‹å¦‚ [["ç‹‚é¼ ", 0.05]] è¡¨ç¤º: å¦‚æœé˜Ÿä¼1å¸¦äº†â€œç‹‚é¼ â€ï¼Œé˜Ÿä¼1èƒœç‡è¦ -0.05
LOW_PRIORITY_HEROES_PENALTY = [
    ["ç‹‚é¼ ", 0.05],
    ["è±å› å“ˆç‰¹", 0.04],
    ["é»‘ç™¾åˆ", 0.01],
    ["ç”Ÿå‘½ä¹‹æ¢­", 0], # æˆ‘è®¨åŒä½  ç”Ÿå‘½ä¹‹æ¢­ ç©ç”Ÿå‘½ä¹‹æ¢­çš„éƒ½æ˜¯ntï¼ï¼ï¼
    ["è«ä¼Šæ‹‰", 0.05],
]

# =========================
# è´Ÿå‘å…‹åˆ¶é“¾ (é™ä½èƒœç‡)
# =========================

HERO_FLOATS = {
    "è±å› å“ˆç‰¹": 0.08,
    "æ¸©æ–¯é¡¿": 0.12,
    "D.Va": 0.08,
    "è·¯éœ¸": 0.09,
    "æŸ¥è‰å¨…": 0.05,
    "æœ«æ—¥é“æ‹³": 0.09,
    "å¥¥ä¸½è": 0.07,
    "ç ´åçƒ": 0.12,
    "æ¯›åŠ ": 0.09,
    "è¥¿æ ¼ç›": 0.07,
    "æ¸£å®¢å¥³ç‹": 0.08,
    "æ‹‰ç›åˆ¹": 0.09,
    "éª‡ç¾": 0.08,

    # =====================================
    # è¾“å‡ºï¼ˆDPSï¼‰
    # =====================================
    "æ­»ç¥": 0.09,
    "çŒç©º": 0.10,
    "åŠè—": 0.07,
    "æ‰˜æ¯”æ˜‚": 0.06,
    "æ³•è€ä¹‹é¹°": 0.10,
    "é»‘ç™¾åˆ": 0.08,
    "å ¡å’": 0.10,
    "ç§©åºä¹‹å…‰": 0.07,
    "æºæ°": 0.08,
    "å¡è¥¿è¿ª": 0.05,
    "ç‹‚é¼ ": 0.12,
    "å£«å…µï¼š76": 0.06,
    "ç¾": 0.07,
    "é»‘å½±": 0.08,
    "ç´¢æ°æ©": 0.05,
    "è‰¾ä»€": 0.07,
    "å›å£°": 0.08,
    "æ¢å¥‡": 0.00,

    # =====================================
    # è¾…åŠ©è‹±é›„ï¼ˆSupportï¼‰
    # =====================================
    "å¤©ä½¿": 0.09,
    "ç¦…é›…å¡”": 0.12,
    "å¢è¥¿å¥¥": 0.06,
    "å®‰å¨œ": 0.13,
    "å·´è’‚æ–¯ç‰¹": 0.07,
    "è«ä¼Šæ‹‰": 0.08,
    "é›¾å­": 0.06,
    "ç”Ÿå‘½ä¹‹æ¢­": 0.09,
    "ä¼Šæ‹‰é”": 0.10,
    "æœ±è¯º": 0.06,
}

# åˆå¹¶ COUNTER_PAIRS å’Œæµ®åŠ¨å€¼ HERO_FLOATS
COUNTER_PAIRS_NEG = [
    [hero[0], hero[1], HERO_FLOATS.get(hero[0], 0)]  # ä½¿ç”¨å­—å…¸çš„æµ®åŠ¨å€¼ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¯¥è‹±é›„ï¼Œé»˜è®¤å€¼ä¸º0
    for hero in constants.COUNTER_PAIRS
]


# =========================
# ğŸ”„ åŠ è½½æ¨¡å‹ & ç¼–ç å™¨
# =========================
def load_model(model_name):
    model_path = os.path.join(MODEL_DIR, f"{model_name}.joblib")
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹ '{model_name}' ä¸å­˜åœ¨ï¼")
        return None
    return joblib.load(model_path)

def load_encoders():
    try:
        mlb_heroes = joblib.load(os.path.join(MODEL_DIR, "MLB_HEROES.joblib"))
        lb_maps = joblib.load(os.path.join(MODEL_DIR, "LB_MAPS.joblib"))
        return mlb_heroes, lb_maps
    except Exception as e:
        print(f"âš ï¸ ç¼–ç å™¨åŠ è½½å¤±è´¥: {e}")
        return None, None

# =========================
# ğŸ”§ ç‰¹å¾æ„é€ 
# =========================
def build_feature_matrix(team_1_heroes, team_2_heroes, map_name, mlb_heroes, lb_maps):
    team1_encoded = mlb_heroes.transform([team_1_heroes])
    team2_encoded = mlb_heroes.transform([team_2_heroes])

    if map_name not in lb_maps.classes_:
        print(f"âš ï¸ åœ°å›¾ '{map_name}' ä¸åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼Œå°†è§†ä¸ºæœªçŸ¥åœ°å›¾ (å…¨é›¶å‘é‡)ã€‚")
        map_encoded = np.zeros((1, len(lb_maps.classes_)))
    else:
        map_encoded = lb_maps.transform([map_name])

    X_matrix = np.hstack([team1_encoded, team2_encoded, map_encoded])
    return X_matrix

# =========================
# ğŸ” è·å–è‹±é›„è§’è‰²
# =========================
def get_role(hero):
    if hero in constants.TANK_HEROES:
        return "Tank"
    elif hero in constants.DPS_HEROES:
        return "DPS"
    elif hero in constants.SUPPORT_HEROES:
        return "Support"
    return None

# =========================
# ğŸ› ï¸ è´Ÿå‘æ•ˆæœ: ä½ä¼˜å…ˆçº§ & è¢«å…‹åˆ¶
# =========================
def apply_negative_effect(team_1, team_2):
    """
    è®¡ç®—é˜Ÿä¼1çš„æ‰€æœ‰è´Ÿå‘æ•ˆæœï¼ŒåŒ…æ‹¬ï¼š
    1. ä½ä¼˜å…ˆçº§è‹±é›„çš„æƒ©ç½š
    2. è¢«å¯¹æ–¹è‹±é›„å…‹åˆ¶çš„æƒ©ç½šï¼ˆåŒä¸€è‹±é›„è¢«å¤šä¸ªå…‹åˆ¶æ—¶å åŠ ï¼‰
    3. å¦‚æœåŒä¸€è‹±é›„åœ¨ COUNTER_PAIRS_NEG ä¸­æœ‰å¤šä¸ªæ¡ç›®ï¼Œåˆ™å–å¹³å‡æƒé‡
    """
    penalty = 0.0



    # 2) è®¡ç®—å…‹åˆ¶é“¾çš„æƒ©ç½š
    counter_penalties = {}  # ç”¨äºå­˜å‚¨ {è¢«å…‹åˆ¶è‹±é›„: [å¤šä¸ªæƒé‡å€¼]}
    
    for hero1, hero2_list, val in COUNTER_PAIRS_NEG:
        if hero1 in team_1:
            for hero2 in hero2_list:
                if hero2 in team_2:
                    if hero1 not in counter_penalties:
                        counter_penalties[hero1] = []
                    counter_penalties[hero1].append(val)

    # è®¡ç®—å…‹åˆ¶çš„å¹³å‡æƒé‡ï¼Œå¹¶ç´¯åŠ æ€» penalty
    for hero, values in counter_penalties.items():
        avg_penalty = sum(values) / len(values)  # å–å¹³å‡å€¼
        penalty += avg_penalty


    for hero, val in LOW_PRIORITY_HEROES_PENALTY:
        if hero in team_1:
            penalty += val

    # 3) ç¡®ä¿ penalty ä¸ä¼šè¿‡é«˜ï¼Œå¯¼è‡´èƒœç‡å˜æˆè´Ÿæ•°
    penalty = min(penalty, 0.65)  # é™åˆ¶æœ€å¤§å‰Šå‡å€¼ï¼ˆå¯è°ƒæ•´ï¼‰

    return penalty

# =========================
# ğŸ”® å•æ¬¡é¢„æµ‹ï¼ˆå¸¦æƒ©ç½šï¼‰
# =========================
def single_predict(model_name, team_1, team_2, map_name):
    """
    è®¡ç®—å•æ¬¡èƒœç‡ï¼Œå¹¶åº”ç”¨è´Ÿé¢æƒ©ç½š
    """
    model = load_model(model_name)
    if model is None:
        return None
    mlb_heroes, lb_maps = load_encoders()
    if mlb_heroes is None or lb_maps is None:
        return None

    # 1) ä½¿ç”¨æ¨¡å‹å¾—åˆ°åŸºç¡€èƒœç‡
    X = build_feature_matrix(team_1, team_2, map_name, mlb_heroes, lb_maps)
    p = model.predict_proba(X)[0][1]

    # 2) è®¡ç®—è´Ÿå‘å½±å“
    penalty = apply_negative_effect(team_1, team_2)
    p -= penalty

    # 3) ç¡®ä¿ p åœ¨ [0, 1] èŒƒå›´
    p = max(0.0, min(1.0, p))
    return p


# =========================
# æ— åè§é¢„æµ‹
# =========================
def predict_no_bias(model_name, team_1, team_2, map_name):
    """
    åšä¸¤æ¬¡é¢„æµ‹ï¼š
        pA = single_predict(team_1 vs team_2)
        pB = single_predict(team_2 vs team_1)
    ç„¶åè®¡ç®— (pA + (1 - pB)) / 2 æ¥æ¶ˆé™¤æ¨¡å‹çš„åè§ã€‚
    """
    pA = single_predict(model_name, team_1, team_2, map_name)
    pB = single_predict(model_name, team_2, team_1, map_name)
    if pA is None or pB is None:
        return None
    corrected_prob = (pA + (1 - pB)) / 2
    return corrected_prob

# =========================
# æŒ‡å®šè‹±é›„æ¢äºº (å¼ºåˆ¶)
# =========================
def replacement(model_name, team_1, team_2, map_name, out_hero, team="team_1"):
    """
    å¼ºåˆ¶æ¢æ‰ out_heroï¼Œæ¢æˆç›¸åŒè§’è‰²çš„å…¶ä»–è‹±é›„ï¼Œé€‰èƒœç‡æå‡æœ€å¤§çš„é‚£ä¸ªã€‚
    è¿”å›: (orig_win_prob, (best_in_hero, new_win_prob, delta)) æˆ– (orig_win_prob, None)
    """
    if team == "team_1":
        target_team, other_team = team_1[:], team_2
    elif team == "team_2":
        target_team, other_team = team_2[:], team_1
    else:
        print("âŒ team å‚æ•°é”™è¯¯ï¼Œåªèƒ½æ˜¯ 'team_1' æˆ– 'team_2'")
        return None, None

    if out_hero not in target_team:
        print(f"æ— æ³•æ¢äººï¼šé˜Ÿä¼ä¸­æ²¡æœ‰[{out_hero}]")
        return None, None

    idx = target_team.index(out_hero)
    role = get_role(out_hero)
    if not role:
        print(f" è‹±é›„[{out_hero}]è§’è‰²æœªçŸ¥ï¼Œè·³è¿‡")
        return None, None

    if role == "Tank":
        candidate_pool = constants.TANK_HEROES
    elif role == "DPS":
        candidate_pool = constants.DPS_HEROES
    else:
        candidate_pool = constants.SUPPORT_HEROES

    orig_win_prob = predict_no_bias(model_name, team_1, team_2, map_name)
    if orig_win_prob is None:
        return None, None

    best_swap_info = None
    best_delta = 0.0

    # é€ä¸€å°è¯•æ›¿æ¢
    for hero_in in candidate_pool:
        if hero_in == out_hero or hero_in in target_team or hero_in in other_team:
            continue

        new_team = target_team[:]
        new_team[idx] = hero_in

        if team == "team_1":
            new_win_prob = predict_no_bias(model_name, new_team, team_2, map_name)
        else:
            new_win_prob = predict_no_bias(model_name, team_1, new_team, map_name)

        if new_win_prob is None:
            continue

        delta = new_win_prob - orig_win_prob
        if delta > best_delta:
            best_delta = delta
            best_swap_info = (hero_in, new_win_prob, delta)

    return orig_win_prob, best_swap_info

# =========================
# AI è‡ªåŠ¨æ¨èæ¢äºº (æŒ‡å®šé˜Ÿä¼)
# =========================
def auto_team_swap(model_name, team_1, team_2, map_name, team="team_1"):
    """
    è‡ªåŠ¨åˆ†æé˜Ÿä¼ï¼Œéå†æ¯ä¸ªè‹±é›„ï¼Œç”¨ç›¸åŒè§’è‰²çš„å…¶å®ƒè‹±é›„æ›¿æ¢ï¼Œé€‰å‡ºèƒ½æœ€å¤§æå‡èƒœç‡çš„æ–¹æ¡ˆ
    è¿”å›: (orig_win_prob, out_hero, in_hero, new_win_prob, delta)
    """
    if team == "team_1":
        target_team, other_team = team_1[:], team_2
    elif team == "team_2":
        target_team, other_team = team_2[:], team_1
    else:
        print(" team å‚æ•°é”™è¯¯ï¼Œåªèƒ½æ˜¯ 'team_1' æˆ– 'team_2'")
        return None, None, None, None, 0.0

    orig_win_prob = predict_no_bias(model_name, team_1, team_2, map_name)
    if orig_win_prob is None:
        return None, None, None, None, 0.0

    best_out = None
    best_in = None
    best_new_prob = None
    best_delta = 0.0

    for i, old_hero in enumerate(target_team):
        role = get_role(old_hero)
        if not role:
            continue

        if role == "Tank":
            candidate_pool = constants.TANK_HEROES
        elif role == "DPS":
            candidate_pool = constants.DPS_HEROES
        else:
            candidate_pool = constants.SUPPORT_HEROES

        # é€ä¸€å°è¯•
        for hero_in in candidate_pool:
            if hero_in == old_hero or hero_in in target_team or hero_in in other_team:
                continue

            new_team = target_team[:]
            new_team[i] = hero_in

            if team == "team_1":
                new_win_prob = predict_no_bias(model_name, new_team, team_2, map_name)
            else:
                new_win_prob = predict_no_bias(model_name, team_1, new_team, map_name)

            if new_win_prob is None:
                continue

            delta = new_win_prob - orig_win_prob
            if delta > best_delta:
                best_delta = delta
                best_out = old_hero
                best_in = hero_in
                best_new_prob = new_win_prob

    return orig_win_prob, best_out, best_in, best_new_prob, best_delta